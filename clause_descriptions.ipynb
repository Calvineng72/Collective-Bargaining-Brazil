{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import io\n",
    "from itertools import dropwhile, takewhile\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# more stop words, valid/not valid, acordo coletivo and not ammendments (extrato)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets the output directory\n",
    "cba_path = os.path.join(\".\", \"clause_data\")\n",
    "if not os.path.isdir(cba_path):\n",
    "    os.mkdir(cba_path)\n",
    "\n",
    "# sets the input directory\n",
    "file_path = os.getcwd() + '/cbas'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# theme and translation dictionaries for clause_groups\n",
    "clause_groups = pd.read_csv('clause_groups.csv', index_col='Clause Group')\n",
    "translation_dict = clause_groups['Translation'].to_dict()\n",
    "themes = list(map(str, clause_groups['Theme'].unique()))\n",
    "theme_dict = clause_groups['Theme'].to_dict()\n",
    "\n",
    "def extract_clauses(file_path, clause_type):\n",
    "    with io.open(file_path, 'r') as f:\n",
    "        # removes white space from the ends of lines\n",
    "        lines = (line.strip() for line in f)  \n",
    "    \n",
    "        # extracts the types of clauses present\n",
    "        clause_flag_start = dropwhile(lambda line: '<STARTofCLAUSES>' not in line, lines)\n",
    "        next(clause_flag_start,\"\")\n",
    "        clause_flag_end = takewhile(lambda line: '<ENDofCLAUSES>' not in line, clause_flag_start)\n",
    "        themes = []\n",
    "        titles = []\n",
    "        for line in clause_flag_end:\n",
    "            if not line: \n",
    "                continue  \n",
    "            title = line.split('|')[0]\n",
    "            translation = translation_dict[title]\n",
    "            titles.append(translation)\n",
    "            theme = theme_dict[title]\n",
    "            themes.append(theme)\n",
    "\n",
    "        # extracts the text of clauses\n",
    "        text_flag_start = dropwhile(lambda line: '<STARTofTEXT>' not in line, lines)\n",
    "        next(text_flag_start, \"\")\n",
    "        texts = []\n",
    "        text = []\n",
    "        for line in text_flag_start:\n",
    "            if '|' in line: \n",
    "                text.append(line.split('|')[0])\n",
    "                texts.append((' ').join(text))\n",
    "                text = []\n",
    "            else:\n",
    "                text.append(line)\n",
    "        if text:\n",
    "            texts.append((' ').join(text))\n",
    "\n",
    "        # retains clauses of proper type\n",
    "        indices_of_type = [i for i, theme in enumerate(themes) if theme == clause_type]\n",
    "        titles_of_type = [titles[i] for i in indices_of_type]\n",
    "        texts_of_type = [texts[i] for i in indices_of_type]\n",
    "\n",
    "        return titles_of_type, texts_of_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Non-compliance with Agreement', 'Renewal / Termination of the Agreement'],\n",
       " ['Em caso de descumprimento do presente acordo, a empresa pagará multa de um piso da categoria, que será revertido em favor do empregado prejudicado. ',\n",
       "  'O presente acordo deverá ter uma via depositada no órgão regional do\\xa0 Ministério do Trabalho, tendo validade pelo prazo de dois anos, a contar de 01/01/2014, podendo ser revogado ou prorrogado por outro acordo, conforme a conveniência das partes acordantes. E por estarem justas e acordadas as partes\\xa0 firmam o presente acordo em 03 (três) vias de igual forma e teor para que produza os efeitos legais. '])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_clauses('cbas/2014_01_01__2014_081501.txt', 'Contract Agreement')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_all(file_path_x, files_x, clause_type):\n",
    "    # only considers files with start dates 2008-2017\n",
    "    if files_x[0:4].isdigit() and 2008 <= int(files_x[0:4]) <= 2017:\n",
    "        # contract identifier\n",
    "        contract_id = [files_x[-15:-4]]\n",
    "        if len(files_x[-15:-4]) != 11:\n",
    "            pass\n",
    "        titles, texts = extract_clauses(os.path.join(file_path_x, files_x), clause_type)\n",
    "        # saves info for contract as a single new line\n",
    "        pairs = [(contract_id + [title, text]) for title, text in zip(titles, texts)]\n",
    "        with io.open(path_txt, 'a', encoding='utf8') as f:\n",
    "            for pair in pairs:\n",
    "                pair_line = '|'.join(str(x) for x in pair)\n",
    "                f.write(pair_line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for theme in themes: \n",
    "    file_name = theme.lower().replace(' / ', '_').replace(' ', '_')\n",
    "\n",
    "    # rewrites output file\n",
    "    path_txt = os.path.join(cba_path, f\"{file_name}_text.csv\")\n",
    "    with io.open(path_txt,'w',encoding='utf8') as f:\n",
    "        header = 'contract_id|title|text'\n",
    "        f.write(header + '\\n')\n",
    "\n",
    "    # loops over each contract\n",
    "    [output_all(file_path, files, theme) for files in os.listdir(file_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "\n",
    "# stop_words = set(stopwords.words('portuguese'))\n",
    "# stemmer = SnowballStemmer('portuguese')\n",
    "# translator = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "# def clean_text(text):\n",
    "#     tokens = word_tokenize(text, language='portuguese')\n",
    "#     tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "#     tokens = [stemmer.stem(word) for word in tokens]\n",
    "#     tokens = [word.translate(translator) for word in tokens]\n",
    "#     tokens = [word for word in tokens if word.isalpha()]\n",
    "#     cleaned_text = ' '.join(tokens).lower()\n",
    "#     return cleaned_text\n",
    "\n",
    "# for theme in themes:\n",
    "#     file_name = theme.lower().replace(' / ', '_').replace(' ', '_')\n",
    "#     df = pd.read_csv(f'clause_data/{file_name}_text.csv', sep='|')\n",
    "#     df['clean_text'] = df['text'].apply(clean_text)\n",
    "#     df.to_csv(f'clause_data/{file_name}_text.csv', sep='|', index=False)\n",
    "\n",
    "# lemmatization package\n",
    "nlp = spacy.load('pt_core_news_sm')\n",
    "stop_words = nlp.Defaults.stop_words\n",
    "\n",
    "# adds custom stop words\n",
    "custom_stop_words = ['parágrafo', 'nº']\n",
    "for word in custom_stop_words:\n",
    "    stop_words.add(word)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_.lower() for token in doc if not token.is_stop and token.is_alpha]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "for theme in themes:\n",
    "    # reads file as csv\n",
    "    file_name = theme.lower().replace(' / ', '_').replace(' ', '_')\n",
    "    df = pd.read_csv(f'clause_data/{file_name}_text.csv', sep='|')\n",
    "\n",
    "    # cleans the text\n",
    "    df['clean_text'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "    # calculatues TFIDF\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(df['clean_text'])\n",
    "    tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "    df = pd.concat([df, tfidf_df], axis=1)\n",
    "\n",
    "    # saves to csv\n",
    "    df.to_csv(f'clause_data/{file_name}_text.csv', sep='|', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 words for \"Wages\":\n",
      "['salário', 'hora', 'ser', 'empregado', 'dia', 'pagamento', 'empresa', 'salarial', 'trabalho', 'real', 'pagar', 'cláusula', 'adiantamento', 'ficar', 'compensação', 'acordo', 'reajuste', 'piso', 'desconto', 'efetuar']\n",
      "\n",
      "Top 20 words for \"Health\":\n",
      "['médico', 'empregado', 'empresa', 'ser', 'exame', 'odontológico', 'atestado', 'convênio', 'profissional', 'caso', 'serviço', 'trabalho', 'empregador', 'sindicato', 'saúde', 'dia', 'plano', 'reconhecer', 'estar', 'fornecer']\n",
      "\n",
      "Top 20 words for \"Union\":\n",
      "['empresa', 'sindicato', 'empregado', 'ser', 'dia', 'trabalho', 'profissional', 'sindical', 'acordo', 'contribuição', 'desconto', 'categoria', 'entidade', 'descontar', 'trabalhador', 'coletivo', 'salário', 'empregador', 'pagamento', 'prazo']\n",
      "\n",
      "Top 20 words for \"Safety / Injury / Disability\":\n",
      "['empresa', 'empregado', 'dia', 'trabalho', 'ser', 'cipa', 'acidente', 'equipamento', 'proteção', 'risco', 'uso', 'prazo', 'fornecer', 'dever', 'sindicato', 'individual', 'ficar', 'caso', 'profissional', 'período']\n",
      "\n",
      "Top 20 words for \"Work Adaptation / Training\":\n",
      "['serviço', 'empregado', 'militar', 'empresa', 'prestação', 'dia', 'idade', 'emprego', 'alistamento', 'trabalho', 'salário', 'guerra', 'tiro', 'ser', 'trinto', 'estabilidade', 'ficar', 'função', 'garantir', 'data']\n",
      "\n",
      "Top 20 words for \"Work Time\":\n",
      "['hora', 'dia', 'trabalho', 'ser', 'empregado', 'empresa', 'jornada', 'férias', 'remunerar', 'ficar', 'trabalhar', 'período', 'caso', 'adicional', 'lei', 'normal', 'licença', 'acordo', 'útil', 'domingo']\n",
      "\n",
      "Top 20 words for \"Incentives\":\n",
      "['empresa', 'empregado', 'ser', 'serviço', 'pagar', 'dia', 'salário', 'mesmo', 'real', 'trabalho', 'ano', 'alimentação', 'ficar', 'receber', 'trabalhador', 'premio', 'domingo', 'refeição', 'caixa', 'ter']\n",
      "\n",
      "Top 20 words for \"Food / Education / Housing\":\n",
      "['empregado', 'empresa', 'transporte', 'fornecer', 'ser', 'real', 'trabalho', 'empregador', 'trabalhador', 'lei', 'dia', 'alimentação', 'vale', 'serviço', 'ficar', 'salário', 'decreto', 'refeição', 'conceder', 'despesa']\n",
      "\n",
      "Top 20 words for \"Contract Agreement\":\n",
      "['acordo', 'multa', 'presente', 'cláusula', 'trabalho', 'coletivo', 'descumprimento', 'empregado', 'empresa', 'sindicato', 'prejudicar', 'ser', 'categoria', 'caso', 'ficar', 'parte', 'condição', 'reverter', 'empregar', 'convenção']\n",
      "\n",
      "Top 20 words for \"Retirement\":\n",
      "['empregado', 'aposentadoria', 'empresa', 'ano', 'serviço', 'período', 'prazo', 'mínimo', 'direito', 'salário', 'trabalhador', 'emprego', 'ficar', 'aquisição', 'aposentar', 'estar', 'dia', 'idade', 'caso', 'garantia']\n",
      "\n",
      "Top 20 words for \"Work Environment / Harassment\":\n",
      "['uniforme', 'empregado', 'empresa', 'uso', 'exigir', 'gratuitamente', 'fornecer', 'trabalho', 'água', 'ficar', 'acordo', 'empregador', 'fornecimento', 'condição', 'ser', 'manter', 'potável', 'fornecir', 'gratuito', 'mesmo']\n",
      "\n",
      "Top 20 words for \"Family\":\n",
      "['empresa', 'empregado', 'empregada', 'dia', 'seguro', 'salário', 'caso', 'ser', 'trabalho', 'cláusula', 'estabilidade', 'gestante', 'licença', 'auxílio', 'falecimento', 'ficar', 'vida', 'conforme', 'idade', 'justa']\n",
      "\n",
      "Top 20 words for \"Dismissals / Transfers\":\n",
      "['empregado', 'aviso', 'empresa', 'dia', 'prévio', 'ano', 'ser', 'trabalho', 'rescisão', 'dispensa', 'contrato', 'justa', 'causa', 'serviço', 'escrito', 'demissão', 'caso', 'homologação', 'prazo', 'dispensar']\n",
      "\n",
      "Top 20 words for \"Fees\":\n",
      "['trabalhar', 'dia', 'pagamento', 'ser', 'citar', 'comissionista', 'comissionistas', 'expediente', 'ficar', 'garantido', 'garantir', 'pagar', 'remunerado', 'trabalhadores', 'vendedor', 'acima', 'real', 'repouso', 'semanal', 'empresa']\n",
      "\n",
      "Top 20 words for \"Staffing / Hiring / Outsourcing\":\n",
      "['empresa', 'empregado', 'função', 'contrato', 'ser', 'salário', 'mesmo', 'dia', 'trabalho', 'experiência', 'caso', 'prazo', 'ctps', 'contratação', 'hora', 'trabalhador', 'teste', 'rescisão', 'ficar', 'pagamento']\n",
      "\n",
      "Top 20 words for \"Other\":\n",
      "['empregado', 'empresa', 'trabalho', 'dia', 'ser', 'salário', 'hora', 'ficar', 'acordo', 'sindicato', 'pagamento', 'presente', 'empregador', 'caso', 'período', 'profissional', 'ano', 'trabalhador', 'ter', 'contrato']\n",
      "\n",
      "Top 20 words for \"Equality / Fairness\":\n",
      "['ser', 'pagar', 'participação', 'empregado', 'empresa', 'dia', 'lucros', 'pagamento', 'programa', 'lucro', 'plr', 'período', 'substituição', 'função', 'presente', 'trabalho', 'resultados', 'instrumento', 'estabelecer', 'resultado']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for theme in themes:\n",
    "    # reads file as csv\n",
    "    file_name = theme.lower().replace(' / ', '_').replace(' ', '_')\n",
    "    df = pd.read_csv(f'clause_data/{file_name}_text.csv', sep='|')\n",
    "\n",
    "    # selects 20 tokens with highest TFIDF\n",
    "    tfidf_cols = [col for col in df.columns if col not in ['text', 'clean_text']]\n",
    "    tfidf_means = df.select_dtypes(include=['float64']).mean()\n",
    "    top_twenty = tfidf_means.nlargest(20)\n",
    "\n",
    "    # prints the top 20 words\n",
    "    print(f'Top 20 words for \"{theme}\":')\n",
    "    print(list(top_twenty.index))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
