{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import io\n",
    "from itertools import dropwhile, takewhile\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets the output directory\n",
    "cba_path = os.path.join(\".\", \"clause_data\")\n",
    "if not os.path.isdir(cba_path):\n",
    "    os.mkdir(cba_path)\n",
    "\n",
    "# sets the input directory\n",
    "file_path = os.getcwd() + '/cbas'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "clause_groups = pd.read_csv('clause_groups.csv', index_col='Clause Group')\n",
    "translation_dict = clause_groups['Translation'].to_dict()\n",
    "themes = list(map(str, clause_groups['Theme'].unique()))\n",
    "theme_dict = clause_groups['Theme'].to_dict()\n",
    "\n",
    "def extract_clauses(file_path, clause_type):\n",
    "    with io.open(file_path, 'r') as f:\n",
    "        # removes white space from the ends of lines\n",
    "        lines = (line.strip() for line in f)  \n",
    "    \n",
    "        # extracts the types of clauses present\n",
    "        clause_flag_start = dropwhile(lambda line: '<STARTofCLAUSES>' not in line, lines)\n",
    "        next(clause_flag_start,\"\")\n",
    "        clause_flag_end = takewhile(lambda line: '<ENDofCLAUSES>' not in line, clause_flag_start)\n",
    "        themes = []\n",
    "        titles = []\n",
    "        for line in clause_flag_end:\n",
    "            if not line: \n",
    "                continue  \n",
    "            title = line.split('|')[0]\n",
    "            translation = translation_dict[title]\n",
    "            titles.append(translation)\n",
    "            theme = theme_dict[title]\n",
    "            themes.append(theme)\n",
    "\n",
    "        # extracts the text of clauses\n",
    "        text_flag_start = dropwhile(lambda line: '<STARTofTEXT>' not in line, lines)\n",
    "        next(text_flag_start, \"\")\n",
    "        texts = []\n",
    "        text = []\n",
    "        for line in text_flag_start:\n",
    "            if '|' in line: \n",
    "                text.append(line.split('|')[0])\n",
    "                texts.append((' ').join(text))\n",
    "                text = []\n",
    "            else:\n",
    "                text.append(line)\n",
    "        if text:\n",
    "            texts.append((' ').join(text))\n",
    "\n",
    "        # finds all clauses of the corresponding type\n",
    "        index_list = []\n",
    "        for index, theme in enumerate(themes):\n",
    "            if theme == clause_type:\n",
    "                index_list.append(index)\n",
    "\n",
    "        # retains clauses of proper type\n",
    "        # titles_of_type = list(itemgetter(*index_list)(titles))\n",
    "        # texts_of_type = list(itemgetter(*index_list)(texts))\n",
    "        titles_of_type = [titles[i] for i in index_list]\n",
    "        texts_of_type = [texts[i] for i in index_list]\n",
    "\n",
    "        \n",
    "        return titles_of_type, texts_of_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Non-compliance with Agreement', 'Renewal / Termination of the Agreement'],\n",
       " ['Em caso de descumprimento do presente acordo, a empresa pagará multa de um piso da categoria, que será revertido em favor do empregado prejudicado. ',\n",
       "  'O presente acordo deverá ter uma via depositada no órgão regional do\\xa0 Ministério do Trabalho, tendo validade pelo prazo de dois anos, a contar de 01/01/2014, podendo ser revogado ou prorrogado por outro acordo, conforme a conveniência das partes acordantes. E por estarem justas e acordadas as partes\\xa0 firmam o presente acordo em 03 (três) vias de igual forma e teor para que produza os efeitos legais. '])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_clauses('cbas/2014_01_01__2014_081501.txt', 'Contract Agreement')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_all(file_path_x, files_x, clause_type):\n",
    "    # only consider files with start dates 2008-2017\n",
    "    #if files_x[0:4]=='2008':\n",
    "    if files_x[0:4]=='2008' or files_x[0:4]=='2009' or files_x[0:4]=='2010' or files_x[0:4]=='2011' or files_x[0:4]=='2012' \\\n",
    "    or files_x[0:4]=='2013' or files_x[0:4]=='2014' or files_x[0:4]=='2015' or files_x[0:4]=='2016' or files_x[0:4]=='2017':\n",
    "        # contract identifier\n",
    "        contract_id = [files_x[-15:-4]]\n",
    "        if len(files_x[-15:-4])!=11:\n",
    "            pass\n",
    "        titles, texts = extract_clauses(os.path.join(file_path_x, files_x), clause_type)\n",
    "        # save info for contract as a single new line\n",
    "        with io.open(path_txt,'a',encoding='utf8') as f:\n",
    "            for title, text in zip(titles, texts):\n",
    "                output = contract_id + [title, text]\n",
    "                pair_line = ('|').join(str(x) for x in output)\n",
    "                f.write(pair_line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for theme in themes: \n",
    "    file_name = theme.lower()\n",
    "    file_name = file_name.replace(' / ', '_')\n",
    "    file_name = file_name.replace(' ', '_')\n",
    "\n",
    "    # rewrites output file\n",
    "    path_txt = os.path.join(cba_path, f\"{file_name}_text.csv\")\n",
    "    with io.open(path_txt,'w',encoding='utf8') as f:\n",
    "        header = 'contract_id|title|text'\n",
    "        f.write(header + '\\n')\n",
    "\n",
    "    # loops over each contract\n",
    "    for idx, files in enumerate(os.listdir(file_path)):\n",
    "        output_all(file_path, files, theme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/calvineng/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/calvineng/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "stop_words = set(stopwords.words('portuguese'))\n",
    "stemmer = SnowballStemmer('portuguese')\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "def clean_text(text):\n",
    "    tokens = word_tokenize(text, language='portuguese')\n",
    "    tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "    tokens = [stemmer.stem(word) for word in tokens]\n",
    "    tokens = [word.translate(translator) for word in tokens]\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    cleaned_text = ' '.join(tokens).lower()\n",
    "    return cleaned_text\n",
    "\n",
    "for theme in themes:\n",
    "    file_name = theme.lower().replace(' / ', '_').replace(' ', '_')\n",
    "    df = pd.read_csv(f'clause_data/{file_name}_text.csv', sep='|')\n",
    "    df['clean_text'] = df['text'].apply(clean_text)\n",
    "    df.to_csv(f'clause_data/{file_name}_text.csv', sep='|', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "for theme in themes:\n",
    "    file_name = theme.lower().replace(' / ', '_').replace(' ', '_')\n",
    "    df = pd.read_csv(f'clause_data/{file_name}_text.csv', sep='|')\n",
    "    \n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectorizer.fit(df['clean_text'])\n",
    "    tfidf_matrix = vectorizer.transform(df['clean_text'])\n",
    "    tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "    df = pd.concat([df, tfidf_df], axis=1)\n",
    "    \n",
    "    df.to_csv(f'clause_data/{file_name}_tfidf.csv', sep='|', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theme: Wages\n",
      "empreg      0.070080\n",
      "salári      0.067006\n",
      "hor         0.063453\n",
      "trabalh     0.058312\n",
      "empres      0.045171\n",
      "pagament    0.044556\n",
      "dia         0.037862\n",
      "parágraf    0.037588\n",
      "compens     0.034522\n",
      "cent        0.033940\n",
      "dtype: float64\n",
      "Theme: Health\n",
      "empreg       0.103936\n",
      "médic        0.093047\n",
      "empres       0.080547\n",
      "atest        0.071982\n",
      "exam         0.056712\n",
      "odontológ    0.055023\n",
      "convêni      0.054041\n",
      "trabalh      0.052526\n",
      "parágraf     0.045029\n",
      "cas          0.042661\n",
      "dtype: float64\n",
      "Theme: Union\n",
      "empreg          0.070081\n",
      "trabalh         0.069197\n",
      "empres          0.066717\n",
      "sindicat        0.060030\n",
      "descont         0.051974\n",
      "acord           0.042597\n",
      "cent            0.038997\n",
      "profissional    0.037310\n",
      "dev             0.037268\n",
      "recolh          0.036004\n",
      "dtype: float64\n",
      "Theme: Safety / Injury / Disability\n",
      "empreg     0.090513\n",
      "empres     0.073488\n",
      "trabalh    0.059857\n",
      "dev        0.048508\n",
      "dias       0.043200\n",
      "acident    0.042951\n",
      "cip        0.041360\n",
      "fornec     0.034808\n",
      "risc       0.033132\n",
      "equip      0.032929\n",
      "dtype: float64\n",
      "Theme: Work Adaptation / Training\n",
      "empreg      0.131342\n",
      "servic      0.097167\n",
      "milit       0.084512\n",
      "empres      0.081405\n",
      "alist       0.073940\n",
      "trabalh     0.071857\n",
      "prestaçã    0.068911\n",
      "idad        0.067853\n",
      "dias        0.063259\n",
      "garant      0.060861\n",
      "dtype: float64\n",
      "Theme: Work Time\n",
      "hor         0.089333\n",
      "trabalh     0.079977\n",
      "empreg      0.065826\n",
      "dias        0.054186\n",
      "fér         0.045966\n",
      "empres      0.044651\n",
      "dia         0.044442\n",
      "parágraf    0.038370\n",
      "remuner     0.034779\n",
      "cent        0.034279\n",
      "dtype: float64\n",
      "Theme: Incentives\n",
      "empres     0.089293\n",
      "empreg     0.087985\n",
      "trabalh    0.081421\n",
      "servic     0.058239\n",
      "pag        0.048626\n",
      "valor      0.043457\n",
      "salári     0.043372\n",
      "receb      0.042018\n",
      "premi      0.040922\n",
      "mesm       0.040246\n",
      "dtype: float64\n",
      "Theme: Food / Education / Housing\n",
      "empreg       0.096246\n",
      "trabalh      0.074155\n",
      "empres       0.071129\n",
      "transport    0.061184\n",
      "parágraf     0.053034\n",
      "fornec       0.052325\n",
      "valor        0.047847\n",
      "nº           0.046672\n",
      "aliment      0.040206\n",
      "rea          0.040083\n",
      "dtype: float64\n",
      "Theme: Contract Agreement\n",
      "acord       0.090436\n",
      "empreg      0.067942\n",
      "part        0.066387\n",
      "mult        0.063671\n",
      "trabalh     0.061848\n",
      "cláusul     0.061707\n",
      "present     0.061578\n",
      "colet       0.056877\n",
      "descumpr    0.055891\n",
      "favor       0.052002\n",
      "dtype: float64\n",
      "Theme: Retirement\n",
      "empreg         0.159926\n",
      "empres         0.103757\n",
      "aposentador    0.100622\n",
      "anos           0.093180\n",
      "servic         0.083545\n",
      "temp           0.082249\n",
      "períod         0.078953\n",
      "trabalh        0.074855\n",
      "comprov        0.072447\n",
      "mínim          0.070945\n",
      "dtype: float64\n",
      "Theme: Work Environment / Harassment\n",
      "empreg     0.116317\n",
      "uniform    0.114545\n",
      "empres     0.102960\n",
      "exig       0.102196\n",
      "gratuit    0.099102\n",
      "fornec     0.097866\n",
      "uso        0.089460\n",
      "trabalh    0.070003\n",
      "fic        0.063493\n",
      "águ        0.061834\n",
      "dtype: float64\n",
      "Theme: Family\n",
      "empreg      0.108224\n",
      "empres      0.079393\n",
      "segur       0.053606\n",
      "dias        0.052344\n",
      "trabalh     0.048406\n",
      "salári      0.047016\n",
      "comprov     0.046805\n",
      "cas         0.044710\n",
      "parágraf    0.043011\n",
      "conform     0.040571\n",
      "dtype: float64\n",
      "Theme: Dismissals / Transfers\n",
      "empreg     0.096153\n",
      "trabalh    0.080676\n",
      "avis       0.074146\n",
      "empres     0.068861\n",
      "dispens    0.066911\n",
      "prévi      0.064424\n",
      "dev        0.054806\n",
      "dias       0.054322\n",
      "rescisã    0.047006\n",
      "caus       0.046068\n",
      "dtype: float64\n",
      "Theme: Fees\n",
      "trabalh      0.335987\n",
      "comission    0.238504\n",
      "dia          0.238504\n",
      "garant       0.238504\n",
      "pagament     0.194913\n",
      "remuner      0.131382\n",
      "final        0.119252\n",
      "expedient    0.119252\n",
      "cit          0.119252\n",
      "rea          0.119252\n",
      "dtype: float64\n",
      "Theme: Staffing / Hiring / Outsourcing\n",
      "empreg       0.086727\n",
      "empres       0.080284\n",
      "contrat      0.078110\n",
      "trabalh      0.059431\n",
      "funçã        0.053748\n",
      "salári       0.052891\n",
      "mesm         0.047848\n",
      "experient    0.045083\n",
      "dias         0.037256\n",
      "cas          0.036108\n",
      "dtype: float64\n",
      "Theme: Other\n",
      "empreg      0.070725\n",
      "trabalh     0.059959\n",
      "empres      0.048527\n",
      "dias        0.034715\n",
      "hor         0.033398\n",
      "salári      0.032480\n",
      "fic         0.029634\n",
      "parágraf    0.029103\n",
      "dev         0.028277\n",
      "acord       0.027297\n",
      "dtype: float64\n",
      "Theme: Equality / Fairness\n",
      "lucr        0.079102\n",
      "empreg      0.077886\n",
      "trabalh     0.068191\n",
      "particip    0.067880\n",
      "pag         0.063817\n",
      "empres      0.062038\n",
      "result      0.059503\n",
      "plr         0.059392\n",
      "dev         0.053373\n",
      "program     0.051912\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for theme in themes:\n",
    "    file_name = theme.lower().replace(' / ', '_').replace(' ', '_')\n",
    "    df = pd.read_csv(f'clause_data/{file_name}_tfidf.csv', sep='|')\n",
    "    \n",
    "    tfidf_cols = [col for col in df.columns if col not in ['text', 'clean_text']]\n",
    "    tfidf_means = df.select_dtypes(include=['float64']).mean()\n",
    "    top_ten = tfidf_means.sort_values(ascending=False)[:10]\n",
    "    \n",
    "    print(f'Theme: {theme}')\n",
    "    print(top_ten)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
