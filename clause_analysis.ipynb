{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import io\n",
    "from itertools import dropwhile, takewhile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets the output directory\n",
    "cba_path = os.path.join(\".\", \"output\")\n",
    "if not os.path.isdir(cba_path):\n",
    "    os.mkdir(cba_path)\n",
    "\n",
    "# sets the input directory\n",
    "file_path = os.getcwd() + '/cbas'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "clause_groups = pd.read_csv('clause_groups.csv', index_col='Clause Group')\n",
    "translation_dict = clause_groups['Translation'].to_dict()\n",
    "themes = list(map(str, clause_groups['Theme'].unique()))\n",
    "theme_dict = clause_groups['Theme'].to_dict()\n",
    "\n",
    "def extract_clauses(file_path):\n",
    "    with io.open(file_path, 'r') as f:\n",
    "        # removes white space from the ends of lines\n",
    "        lines = (line.strip() for line in f)  \n",
    "    \n",
    "        # extracts the types of clauses present\n",
    "        clause_flag_start = dropwhile(lambda line: '<STARTofCLAUSES>' not in line, lines)\n",
    "        next(clause_flag_start,\"\")\n",
    "        clause_flag_end = takewhile(lambda line: '<ENDofCLAUSES>' not in line, clause_flag_start)\n",
    "        themes = []\n",
    "        for line in clause_flag_end:\n",
    "            if not line: \n",
    "                continue  \n",
    "            title = line.split('|')[0]\n",
    "            theme = theme_dict[title]\n",
    "            themes.append(theme)\n",
    "\n",
    "        # extracts the text of clauses\n",
    "        text_flag_start = dropwhile(lambda line: '<STARTofTEXT>' not in line, lines)\n",
    "        next(text_flag_start, \"\")\n",
    "        texts = []\n",
    "        text = []\n",
    "        for line in text_flag_start:\n",
    "            if '|' in line: \n",
    "                texts.append((' ').join(text))\n",
    "                text = []\n",
    "            else:\n",
    "                text.append(line)\n",
    "        if text:\n",
    "            texts.append((' ').join(text))\n",
    "\n",
    "        return themes, texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Contract Agreement', 'Contract Agreement', 'Other', 'Other'],\n",
       " ['Em caso de descumprimento do presente acordo, a empresa pagará multa de um piso da categoria, que será revertido em favor do empregado prejudicado.',\n",
       "  'O presente acordo deverá ter uma via depositada no órgão regional do\\xa0 Ministério do Trabalho, tendo validade pelo prazo de dois anos, a contar de 01/01/2014, podendo ser revogado ou prorrogado por outro acordo, conforme a conveniência das partes acordantes. E por estarem justas e acordadas as partes\\xa0 firmam o presente acordo em 03 (três) vias de igual forma e teor para que produza os efeitos legais.',\n",
       "  'Fica acordado que a partir de 01/01/2014 os empregados poderão trabalhar no dia de domingo que estiver de folga, mediante o pagamento de SERVIÇOS EXTRAS no valor mínimo de R$ 70,00 (setenta reais) pela jornada máxima de sete horas. ',\n",
       "  'A empresa concederá uma folga semanal a\\xa0 todos os seus empregados, nos dias da semana compreendida de segunda-feira a sábado.\\xa0 A folga no domingo prevista na Cláusula sexta da CCT 2014/2016 poderá ser concedida mediante solicitação do empregado, com uma semana de antecedência, de comum acordo com a empresa. Parágrafo Único - As horas extras trabalhadas nos dias de domingos de folga alem da jornada prevista acima serão pagas em dobro.'])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_clauses('cbas/2014_01_01__2014_081501.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_all(file_path_x, files_x):\n",
    "    # only consider files with start dates 2008-2017\n",
    "    #if files_x[0:4]=='2008':\n",
    "    if files_x[0:4]=='2008' or files_x[0:4]=='2009' or files_x[0:4]=='2010' or files_x[0:4]=='2011' or files_x[0:4]=='2012' \\\n",
    "    or files_x[0:4]=='2013' or files_x[0:4]=='2014' or files_x[0:4]=='2015' or files_x[0:4]=='2016' or files_x[0:4]=='2017':\n",
    "        # contract identifier\n",
    "        contract_id = [files_x[-15:-4]]\n",
    "        if len(files_x[-15:-4])!=11:\n",
    "            pass\n",
    "        text = extract_clauses(os.path.join(file_path_x, files_x))\n",
    "        output = contract_id + [text]\n",
    "        pair_line = ('|').join(str(x) for x in output)\n",
    "        # save info for contract as a single new line\n",
    "        with io.open(path_txt,'a',encoding='utf8') as f:\n",
    "            f.write(pair_line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looping through file  2016_09_01__2016_082054.txt\n",
      "Looping through file  2011_11_01__2012_002993.txt\n",
      "Looping through file  2014_01_01__2014_081501.txt\n",
      "Looping through file  2017_12_01__2017_084835.txt\n",
      "Looping through file  2017_12_01__2017_084809.txt\n",
      "Looping through file  2013_11_15__2013_055346.txt\n",
      "Looping through file  2009_01_01__2009_016497.txt\n",
      "Looping through file  2015_06_16__2015_060659.txt\n",
      "Looping through file  2018_05_01__2018_044118.txt\n",
      "Looping through file  2012_05_01__2012_042451.txt\n",
      "Looping through file  2011_11_01__2012_002943.txt\n",
      "Looping through file  2016_09_01__2016_082084.txt\n",
      "Looping through file  2013_11_14__2014_009174.txt\n",
      "Looping through file  2009_01_01__2009_016731.txt\n",
      "Looping through file  2015_05_01__2015_043073.txt\n",
      "Looping through file  2011_11_01__2012_003082.txt\n",
      "Looping through file  2015_12_16__2015_084042.txt\n",
      "Looping through file  2017_12_01__2017_084934.txt\n",
      "Looping through file  2013_06_01__2013_073146.txt\n",
      "Looping through file  2017_03_01__2017_039221.txt\n",
      "Looping through file  2017_03_01__2017_039341.txt\n",
      "Looping through file  2015_06_16__2015_069545.txt\n",
      "Looping through file  2013_11_15__2013_069396.txt\n",
      "Looping through file  2009_01_01__2009_016579.txt\n",
      "Looping through file  2014_01_01__2014_038109.txt\n",
      "Looping through file  2013_06_01__2013_073403.txt\n",
      "Looping through file  2010_04_01__2010_074416.txt\n",
      "Looping through file  2015_01_01__2015_065035.txt\n",
      "Looping through file  2017_03_01__2017_039364.txt\n",
      "Looping through file  2012_05_01__2012_032527.txt\n",
      "Looping through file  2009_01_01__2009_034089.txt\n",
      "Looping through file  2013_11_15__2013_068336.txt\n",
      "Looping through file  2018_05_01__2018_044198.txt\n",
      "Looping through file  2014_01_01__2014_081419.txt\n",
      "Looping through file  2013_06_01__2013_073410.txt\n",
      "Looping through file  2009_01_01__2009_016389.txt\n",
      "Looping through file  2010_04_01__2010_074884.txt\n",
      "Looping through file  2014_01_01__2014_038173.txt\n",
      "Looping through file  2012_05_01__2012_042462.txt\n",
      "Looping through file  2012_05_01__2012_042489.txt\n",
      "Looping through file  2016_09_01__2016_082062.txt\n",
      "Looping through file  2010_04_01__2010_075192.txt\n",
      "Looping through file  2015_05_01__2015_043120.txt\n",
      "Looping through file  2014_01_01__2014_081490.txt\n",
      "Looping through file  2015_06_16__2015_075846.txt\n",
      "Looping through file  2012_05_01__2012_032551.txt\n",
      "Looping through file  2010_04_01__2010_074659.txt\n",
      "Looping through file  2015_05_01__2015_043084.txt\n",
      "Looping through file  2015_12_16__2015_083965.txt\n",
      "Looping through file  2015_06_17__2015_031484.txt\n"
     ]
    }
   ],
   "source": [
    "# rewrites output file\n",
    "path_txt = os.path.join(cba_path, \"clause_text.txt\")\n",
    "with io.open(path_txt,'w',encoding='utf8') as f:\n",
    "    header = 'contract_id|text'\n",
    "    f.write(header + '\\n')\n",
    "    \n",
    "# loops over each contract\n",
    "for idx, files in enumerate(os.listdir(file_path)):\n",
    "    print(\"Looping through file \", files)\n",
    "    output_all(file_path, files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
