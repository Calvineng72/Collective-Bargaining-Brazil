{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import io\n",
    "from itertools import dropwhile, takewhile\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "878283\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contract_id</th>\n",
       "      <th>validity</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010_033261</td>\n",
       "      <td>0</td>\n",
       "      <td>Wage floors</td>\n",
       "      <td>I – Para jornada de trabalho de 36 (trinta e s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009_055971</td>\n",
       "      <td>1</td>\n",
       "      <td>Wage floors</td>\n",
       "      <td>Ficará garantido ao empregado motorista o valo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009_055971</td>\n",
       "      <td>1</td>\n",
       "      <td>Wage payment</td>\n",
       "      <td>Para as funções de motorista de carreta, bi-tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009_055971</td>\n",
       "      <td>1</td>\n",
       "      <td>Wage deductions</td>\n",
       "      <td>Qualquer multa por excesso de velocidade, por ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009_055971</td>\n",
       "      <td>1</td>\n",
       "      <td>Food assistance</td>\n",
       "      <td>Os empregados motoristas externos receberão me...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   contract_id  validity             name  \\\n",
       "0  2010_033261         0      Wage floors   \n",
       "1  2009_055971         1      Wage floors   \n",
       "2  2009_055971         1     Wage payment   \n",
       "3  2009_055971         1  Wage deductions   \n",
       "4  2009_055971         1  Food assistance   \n",
       "\n",
       "                                                text  \n",
       "0  I – Para jornada de trabalho de 36 (trinta e s...  \n",
       "1  Ficará garantido ao empregado motorista o valo...  \n",
       "2  Para as funções de motorista de carreta, bi-tr...  \n",
       "3  Qualquer multa por excesso de velocidade, por ...  \n",
       "4  Os empregados motoristas externos receberão me...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# reads file as csv\n",
    "df = pd.read_csv('clause_data/contract_clauses.csv', sep=\"|\")\n",
    "\n",
    "# keeps only valid ACTs\n",
    "df = df.loc[(df['acordo'] == 1)&(df['extrato'] == 1)]\n",
    "df = df.drop(['acordo', 'extrato'], axis=1)\n",
    "df = df.dropna()\n",
    "\n",
    "# reindexes the dataframe with the default integer index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print(len(df.index))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Medical certificates', 'Union access to information', 'Union access to workplace', 'Work-related injuries', 'Work functions adaptation', 'Overtime pay', 'Hazard pay (health)', 'Night pay', 'Shift pay', 'Hazard pay (danger)', 'On-call pay', 'Seniority pay', 'Subsistence allowance', 'CBA enforcement', 'Retirement', 'Moral harassment', 'Sexual harassment', 'Work function assignment', 'Sundays and holidays', 'Food assistance', 'Childcare assistance', 'Illness assistance', 'Education assistance', 'Housing assistance', 'Maternity assistance', 'Funeral assistance', 'Health assistance', 'Transportation assistance', 'Performance evaluation', 'Advance notice', 'Health education campaigns', 'Accident prevention committee', 'Fees', 'Factory commission', 'Workday compensation', 'Working environment conditions', 'Workday controls', 'Union dues', 'Part-time', '13th month bonus', 'Separations', 'CBA non-compliance', 'Wage deductions', 'Weekly rest', 'Opposition to union dues', 'Vacation days and duration', 'Duration and schedule', 'Loans', 'Equipments for individual safety', 'Safety equipment', 'Abortion protections', 'Injury protections (work-related)', 'Adoption protections', 'Retirement protections', 'Apprenticeship protections', 'Employment protections', 'Maternity protections', 'Paternity protections', 'Injury protections (nonwork-related)', 'Military service protections', 'Medical exams', 'Absences', 'Collective vacations', 'Tools and equipment', 'Guarantees to union officers', 'Nonwork-related injuries', 'Internships', 'Work function bonus', 'Equal opportunity', 'Insalubrity', 'Break intervals', 'Wage isonomy', 'Special shifts', 'Union activities leave', 'Abortion leave', 'Adoption leave', 'Maternity leave', 'Unpaid leave', 'Paid leave', 'Machine and equipment maintenance', 'Advanced-age workforce', 'Female workforce', 'Youth workforce', 'Outsourcing', 'Conflict resolution', 'Disciplinary norms', 'Hiring rules', 'Other pays', 'Other assistances', 'Other bargaining provisions', 'Other time off provisions', 'Other workday provisions', 'Other union-firm provisions', 'Other union provisions', 'Other employment protections', 'Other bonuses', 'Other workforces', 'Other staffing rules', 'Other injury prevention standards', 'Other injury provisions', 'Other contracting', 'Other rules on working conditions', 'Other wage rules', 'Wage payment', 'Worker participation in management', 'Profit sharing', 'Hazards', 'Wage floors', 'Task-and-wage schedule', 'Policies for maintaining employment', 'Policy for dependents', 'Special needs workforce', 'Awards', 'First aid', 'Employment protection program', 'Workday extension/reduction', 'Strikes', 'Health and safety professionals', 'Vocational training', 'Rehabilitation of the injured', 'Wage increases', 'CBA negotiation rules', 'Weekly rest wage', 'Vacation remuneration', 'CBA renewal/termination', 'Union representatives', 'Family salary', 'Intern wage', 'Production wage', 'Life insurance', 'Unionization campaigns', 'On-call shifts', 'Suspensions', 'Transfers', 'Training for injury prevention', 'Uninterrupted shifts', 'Uniforms']\n"
     ]
    }
   ],
   "source": [
    "# theme and translation dictionaries for clause_groups\n",
    "clause_groups = pd.read_csv('clause_groups/clause_groups_NEW.csv', index_col='name_pt')\n",
    "translation_dict = clause_groups['shortened_name_en'].to_dict()\n",
    "translations = list(map(str, clause_groups['shortened_name_en'].unique()))\n",
    "print(translations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name\n",
      "Other bargaining provisions    19714\n",
      "Wage increases                 18208\n",
      "Wage floors                    17097\n",
      "Workday compensation           17094\n",
      "Union dues                     16781\n",
      "Name: contract_id, dtype: int64\n",
      "['Other bargaining provisions', 'Wage increases', 'Wage floors', 'Workday compensation', 'Union dues']\n"
     ]
    }
   ],
   "source": [
    "name_counts = df.groupby('name')['contract_id'].nunique().sort_values(ascending=False)\n",
    "top_five_names = name_counts.head(5).index.tolist()\n",
    "print(name_counts.head())\n",
    "print(top_five_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# lemmatizer\n",
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "\n",
    "# stop words\n",
    "stop_words = nlp.Defaults.stop_words\n",
    "\n",
    "# adds custom stop words\n",
    "custom_stop_words = ['parágrafo', 'nº', 'i', 'ii', 'iii', 'iv', 'v', 'vi', 'vii', 'viii', 'ix', 'x',\n",
    "                     'xi', 'xii', 'xiii', 'xiv', 'xv', 'xvi', 'xvii', 'xviii', 'xix', 'xx', 'xxi',\n",
    "                     'xxii', 'xxiii', 'xxiv', 'xxv', 'xxvi', 'xxvii', 'xxviii', 'xxix', 'xxx', 'number',\n",
    "                     'clt', 'artigo']\n",
    "stop_words.update(custom_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class CBAPreprocessLemmatize(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, preprocess=True, remove_punctuation=True,\n",
    "                 replace_numbers=True, remove_stopwords=True, lemmatize=True):\n",
    "        self.preprocess = preprocess\n",
    "        self.remove_punctuation = remove_punctuation\n",
    "        self.replace_numbers = replace_numbers\n",
    "        self.remove_stopwords = remove_stopwords\n",
    "        self.lemmatize = lemmatize\n",
    "        \n",
    "    def preprocess_text(self, text):\n",
    "        if self.remove_punctuation:\n",
    "            text = re.sub(r'[^\\w\\s]|º|ª', '', text)\n",
    "        if self.replace_numbers:\n",
    "            text = re.sub(r'\\d+(?:\\.\\d*(?:[eE]\\d+))?', 'NUMBER', text)\n",
    "        if self.remove_stopwords:\n",
    "            words = text.split()\n",
    "            words = [word for word in words if word.lower() not in stop_words]\n",
    "            text = ' '.join(words)\n",
    "        if self.lemmatize:\n",
    "            doc = nlp(text)\n",
    "            words = [token.lemma_ for token in doc]\n",
    "            text = ' '.join(words)\n",
    "        return text.lower()\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = [\n",
    "            self.preprocess_text(cba)\n",
    "            for cba in X\n",
    "        ]\n",
    "        return np.array(X_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Other bargaining provisions\n",
      "Best value of C: 1\n",
      "Test accuracy: 0.7051307914733373\n",
      "Top 10 Indicative Features for Other bargaining provisions: ['incentivar', 'dispositivo pactuado', 'convocar', 'emprego conformidade', 'trabalho visar', 'ata assembléia', 'dia término', 'devido processo', 'processo prorrogação', 'excesso']\n",
      "Name: Union dues\n",
      "Best value of C: 1\n",
      "Test accuracy: 0.6949380319546066\n",
      "Top 10 Indicative Features for Union dues: ['enviar respectivo', 'empregado beneficiar', 'outubronumber contribuição', 'repassar décimo', 'recolhimento mensalidade', 'afixar assembléia', 'mobiliário', 'ônus', 'antecedêncer pequeno', 'alimentação']\n",
      "Name: Wage floors\n",
      "Best value of C: 1\n",
      "Test accuracy: 0.7091019663490776\n",
      "Top 10 Indicative Features for Wage floors: ['garantir empregar', 'percebir', 'ocorrência', 'sindicatos patronais', 'político', 'auxiliar produção', 'dispensar', 'acordo nenhum', 'perceber', 'trezento']\n",
      "Name: Wage increases\n",
      "Best value of C: 1\n",
      "Test accuracy: 0.7064346865506766\n",
      "Top 10 Indicative Features for Wage increases: ['majoração salarialos', 'término aprendizagem', 'antecipação reajuste', 'inciso', 'conceder funcionário', 'dever paga', 'empregado abrangir', 'promoção transferênciar', 'rmnr', 'aplicar reajuste']\n",
      "Name: Workday compensation\n",
      "Best value of C: 0.001\n",
      "Test accuracy: 0.7292919376610627\n",
      "Top 10 Indicative Features for Workday compensation: ['útilel ficar', 'empregados prestação', 'empregados trabalho', 'empregados trabalhem', 'empregados trabalhar', 'empregados tomer', 'empregados tiver', 'empregados termo', 'empregados ter', 'empregados tela']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "preprocess_pipeline = Pipeline([\n",
    "    (\"cba_preprocess\", CBAPreprocessLemmatize()),\n",
    "    (\"cba_to_tfidf\", TfidfVectorizer(ngram_range=(1, 2), min_df=0.0001))\n",
    "])\n",
    "\n",
    "groups = df[df['name'].isin(top_five_names)].groupby('name')\n",
    "\n",
    "for name, group in groups:\n",
    "    # applies preprocessing pipeline and calculates TFIDF\n",
    "    X = preprocess_pipeline.fit_transform(group['text'])\n",
    "    y = group['validity']\n",
    "    feature_names = preprocess_pipeline.named_steps['cba_to_tfidf'].get_feature_names_out()\n",
    "\n",
    "    # splits the data for training and testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=253)\n",
    "\n",
    "    # trains a logistic regression model with L1 penalty and liblinear solver\n",
    "    logreg = LogisticRegression(penalty='l1', solver='liblinear', random_state=253)\n",
    "\n",
    "    # finds the best value of C \n",
    "    param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "    grid = GridSearchCV(logreg, param_grid, cv=2)\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_model = grid.best_estimator_\n",
    "\n",
    "    # prints the best value of C and the test accuracy\n",
    "    print(f'Name: {name}')\n",
    "    print(f'Best value of C: {best_model.C}')\n",
    "    print(f'Test accuracy: {best_model.score(X_test, y_test)}')\n",
    "\n",
    "    # gets the top indicative features\n",
    "    coefs = best_model.coef_[0]\n",
    "    top_indicative_features = [feature_names[i] for i in coefs.argsort()[-10:][::-1]]\n",
    "    print(f'Top 10 Indicative Features for {name}:', top_indicative_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
