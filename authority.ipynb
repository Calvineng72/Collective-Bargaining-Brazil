{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isso PRON nsubj\n",
      "aqui ADV advmod\n",
      "é AUX cop\n",
      "uma DET det\n",
      "frase NOUN ROOT\n",
      "simples ADJ amod\n",
      "em ADP case\n",
      "português NOUN nmod\n",
      "usada VERB acl\n",
      "como ADP case\n",
      "exemplo NOUN obl\n",
      "para SCONJ mark\n",
      "ajudar VERB advcl\n",
      "a SCONJ mark\n",
      "entender VERB xcomp\n",
      "o DET det\n",
      "programa NOUN obj\n",
      ". PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('pt_core_news_sm')\n",
    "\n",
    "text = 'Isso aqui é uma frase simples em português usada como exemplo para ajudar a entender o programa.'\n",
    "\n",
    "doc_1 = nlp(text)\n",
    "\n",
    "for token in doc_1:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ao ADP case\n",
      "contrário NOUN obl\n",
      "da ADP case\n",
      "outra DET det\n",
      "frase NOUN nmod\n",
      ", PUNCT punct\n",
      "esta DET det\n",
      "frase NOUN nsubj\n",
      "complexa ADJ amod\n",
      "usa VERB ROOT\n",
      "um DET det\n",
      "verbo NOUN obj\n",
      "melhor ADJ amod\n",
      ", PUNCT punct\n",
      "criando VERB advcl\n",
      "um DET det\n",
      "cenário NOUN obj\n",
      "diferente ADJ amod\n",
      ". PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "text = \"Ao contrário da outra frase, esta frase complexa usa um verbo melhor, criando um cenário diferente.\"\n",
    "\n",
    "doc_2 = nlp(text)\n",
    "\n",
    "for token in doc_2:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding the root of a sentence: https://universaldependencies.org/pt/dep/root.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frase usa\n",
      "\n",
      "frase \t 4 \t NOUN \t ROOT \t [] \t ['Isso', 'aqui', 'é', 'uma', 'simples', 'português', '.']\n",
      "\n",
      "usa \t 9 \t VERB \t ROOT \t [] \t ['contrário', 'frase', 'verbo', 'criando', '.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def find_root_of_sentence(doc):\n",
    "    root_token = None\n",
    "    for token in doc:\n",
    "        if (token.dep_ == \"ROOT\"):\n",
    "            root_token = token\n",
    "    return root_token\n",
    "\n",
    "root_1 = find_root_of_sentence(doc_1)\n",
    "root_2 = find_root_of_sentence(doc_2)\n",
    "print(root_1, root_2)\n",
    "print()\n",
    "\n",
    "ancestors = [t.text for t in root_1.ancestors]\n",
    "children = [t.text for t in root_1.children]\n",
    "print(root_1.text, \"\\t\", root_1.i, \"\\t\", \n",
    "    root_1.pos_, \"\\t\", root_1.dep_, \"\\t\", \n",
    "    ancestors, \"\\t\", children)\n",
    "print()\n",
    "\n",
    "ancestors = [t.text for t in root_2.ancestors]\n",
    "children = [t.text for t in root_2.children]\n",
    "print(root_2.text, \"\\t\", root_2.i, \"\\t\", \n",
    "    root_2.pos_, \"\\t\", root_2.dep_, \"\\t\", \n",
    "    ancestors, \"\\t\", children)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isso\n",
      "frase\n",
      "(Isso, é, frase)\n",
      "(frase, usa, verbo)\n"
     ]
    }
   ],
   "source": [
    "def find_subject(doc):\n",
    "    subject = None\n",
    "    for token in doc:\n",
    "        if (token.dep_ == \"nsubj\"):\n",
    "            subject = token\n",
    "    return subject\n",
    "\n",
    "def extract_clause(doc, root):\n",
    "    subject = find_subject(doc)\n",
    "    noun = None\n",
    "    verb = None\n",
    "    if root.pos_ == \"NOUN\":\n",
    "        noun = root\n",
    "        for child in root.children:\n",
    "            if child.dep_ == \"cop\":\n",
    "                verb = child\n",
    "    elif root.pos_ == \"VERB\":\n",
    "        verb = root\n",
    "        for child in root.children:\n",
    "            if child.dep_ == \"obj\":\n",
    "                noun = child\n",
    "    return (subject, verb, noun)\n",
    "\n",
    "print(extract_clause(doc_1, find_root_of_sentence(doc_1)))\n",
    "print(extract_clause(doc_2, find_root_of_sentence(doc_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estabelecido\n",
      "(que, estabelecido, None)\n",
      "fato\n",
      "(None, None, fato)\n",
      "arquivam\n",
      "(Acordo, arquivam, None)\n"
     ]
    }
   ],
   "source": [
    "sample_text = 'Fica estabelecido que o pagamento do adicional de periculosidade aos empregados da empresa relacionada acima, que façam jus a tais benefícios, nos termos da legislação em vigor, será devido de forma proporcional ao período de exposição ao risco, calculado em conformidade com a planilha assinada pelo empregado e empregador. O fato de ser efetuado o pagamento do percentual correspondente ao índice apurado a título de adicional de periculosidade não exime a empresa signatária do presente instrumento em envidar esforços no sentido da melhoria das condições de trabalho, sendo que, após neutralizado ou eliminado o risco, será indevido o pagamento do referido adicional. E por estarem as partes justas e acordadas, arquivam o presente Acordo Coletivo de Trabalho, perante  a Secretaria de Relações do Trabalho, do Ministério do Trabalho e Emprego em Brasília/DF, para que surtam seus jurídicos e legais efeitos.'\n",
    "sample_doc = nlp(sample_text)\n",
    "sentences = list(sample_doc.sents)\n",
    "len(sentences)\n",
    "\n",
    "for sentence in sentences:\n",
    "    root = find_root_of_sentence(sentence)\n",
    "    print(root)\n",
    "    print(extract_clause(sentence, root))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
